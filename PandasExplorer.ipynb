{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & clean data from Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_excel function\n",
    "median_age = pd.read_excel('Data/median_age.xlsx', engine='openpyxl')\n",
    "\n",
    "# use 'type' function to see what we're working with\n",
    "type(median_age)\n",
    "\n",
    "# use 'info' & 'describe' methods to find out about the dataframe\n",
    "median_age.info()\n",
    "median_age.describe()\n",
    "\n",
    "# use 'astype' to change the Census Tract data type\n",
    "median_age['Census Tract'] = median_age['Census Tract'].astype('str')\n",
    "\n",
    "# remove the decimal from Census Tract column\n",
    "median_age['Census Tract'] = median_age['Census Tract'].str.replace('.', '')\n",
    "\n",
    "# show histogram\n",
    "median_age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & clean data from CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrub the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv function\n",
    "migration_df = pd.read_csv(\n",
    "    'Data/countyinflow2122.csv',\n",
    "    usecols=['y2_countyfips', 'y2_statefips',\n",
    "             'y1_countyfips', 'y1_statefips', 'n2', 'agi']\n",
    ")\n",
    "\n",
    "# because the y1, y2 designations are confusing, replace these with 'origin' and 'dest'\n",
    "new_columns = {\n",
    "    col: col.replace('y1', 'origin', 1).replace('y2', 'dest', 1)\n",
    "    for col in migration_df.columns\n",
    "}\n",
    "migration_df = migration_df.rename(columns=new_columns)\n",
    "\n",
    "# because 'agi' is in thousands, multiply column by 1,000\n",
    "migration_df['agi'] = migration_df['agi'] * 1000\n",
    "\n",
    "# rename 'n2' column\n",
    "migration_df = migration_df.rename(columns={'n2': 'persons'})\n",
    "\n",
    "# create full FIPS codes for origin, destination\n",
    "migration_df['dest_FIPS'] = migration_df['dest_statefips'].astype(\n",
    "    str).str.zfill(2) + migration_df['dest_countyfips'].astype(str).str.zfill(3)\n",
    "migration_df['orig_FIPS'] = migration_df['origin_statefips'].astype(\n",
    "    str).str.zfill(2) + migration_df['origin_countyfips'].astype(str).str.zfill(3)\n",
    "\n",
    "# reduce the number of columns we need\n",
    "migration_df = migration_df[[\n",
    "    'orig_FIPS',\n",
    "    'dest_FIPS',\n",
    "    'persons',\n",
    "    'agi'\n",
    "]]\n",
    "\n",
    "# how to just show Fulton County?\n",
    "migration_df[migration_df['orig_FIPS'] == '13121']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lookup county names from FIPS code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read in CSV to use as dataframe lookup table\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m lookup_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/FIPS_lookup.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIPS\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# ensure FIPS codes are properly zero-padded\u001b[39;00m\n\u001b[1;32m      5\u001b[0m lookup_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIPS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lookup_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIPS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# read in CSV to use as dataframe lookup table\n",
    "lookup_df = pd.read_csv('Data/FIPS_lookup.csv', dtype={'FIPS': 'str'})\n",
    "\n",
    "# ensure FIPS codes are properly zero-padded\n",
    "lookup_df['FIPS'] = lookup_df['FIPS'].str.zfill(5)\n",
    "\n",
    "# Merge to get origin county names\n",
    "migration_2 = migration_df.merge(\n",
    "    lookup_df[['FIPS', 'County_name', 'State']],\n",
    "    how='left',\n",
    "    left_on='orig_FIPS',\n",
    "    right_on='FIPS'\n",
    ").rename(columns={'County_name': 'orig_county', 'State': 'orig_state'})\n",
    "\n",
    "# Drop the extra FIPS column\n",
    "migration_2.drop(columns=['FIPS'], inplace=True)\n",
    "\n",
    "# Merge to get destination county names\n",
    "migration_final = migration_2.merge(\n",
    "    lookup_df[['FIPS', 'County_name', 'State']],\n",
    "    how='left',\n",
    "    left_on='dest_FIPS',\n",
    "    right_on='FIPS'\n",
    ").rename(columns={'County_name': 'dest_county', 'State': 'dest_state'})\n",
    "\n",
    "# Drop the extra FIPS column\n",
    "migration_final.drop(columns=['FIPS'], inplace=True)\n",
    "\n",
    "# rearrange the columns\n",
    "migration_final = migration_final[[\n",
    "    'orig_FIPS',\n",
    "    'orig_county',\n",
    "    'orig_state',\n",
    "    'persons',\n",
    "    'agi',\n",
    "    'dest_FIPS',\n",
    "    'dest_county',\n",
    "    'dest_state'\n",
    "]]\n",
    "\n",
    "migration_final.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get metro Atlanta counties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 29 counties from Wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/Metro_Atlanta\"\n",
    "\n",
    "# use 'read_html' to get the data\n",
    "atl_df = pd.read_html(url)\n",
    "\n",
    "atl_df[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean metro county list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pare down the dataframe\n",
    "atl_df_clean = atl_df[4][[\n",
    "    'County'\n",
    "]]\n",
    "\n",
    "# remove the last row, which totals the counties\n",
    "atl_df_clean = atl_df_clean[atl_df_clean['County'] != 'Total']\n",
    "\n",
    "# remove the \" *\" from the 'County' column\n",
    "atl_df_clean['County'] = atl_df_clean['County'].str.replace(\n",
    "    ' *', '', regex=False)\n",
    "\n",
    "# add the state\n",
    "atl_df_clean['State'] = 'Georgia'\n",
    "\n",
    "# add the FIPS code\n",
    "fips_df = pd.read_csv('Data/FIPS_lookup.csv')\n",
    "fips_df['FIPS'] = fips_df['FIPS'].astype(str).str.zfill(5)\n",
    "\n",
    "# merge the ATL dataframe with the FIPS lookup table\n",
    "atl_df_clean = atl_df_clean.merge(\n",
    "    fips_df,\n",
    "    how='left',\n",
    "    left_on=['County', 'State'],\n",
    "    right_on=['County_name', 'State'],\n",
    ").drop(columns='County_name')\n",
    "\n",
    "# convert the FIPS values to a list\n",
    "atl_fips = list(atl_df_clean['FIPS'])\n",
    "atl_fips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only get migration into / out of metro ATL counties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the migration dataset to only include ATL counties\n",
    "migration_atl = migration_final[migration_final['orig_FIPS'].isin(atl_fips) |\n",
    "                                migration_final['dest_FIPS'].isin(atl_fips)]\n",
    "\n",
    "# print out rows in the dataframe\n",
    "print(migration_atl.shape[0])\n",
    "migration_atl.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>County_name</th>\n",
       "      <th>State</th>\n",
       "      <th>County_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01005</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01007</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01009</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>56037</td>\n",
       "      <td>Sweetwater County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Sweetwater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>56039</td>\n",
       "      <td>Teton County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Teton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>56041</td>\n",
       "      <td>Uinta County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Uinta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>56043</td>\n",
       "      <td>Washakie County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>56045</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3144 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS        County_name    State County_short\n",
       "1     01001     Autauga County  Alabama      Autauga\n",
       "2     01003     Baldwin County  Alabama      Baldwin\n",
       "3     01005     Barbour County  Alabama      Barbour\n",
       "4     01007        Bibb County  Alabama         Bibb\n",
       "5     01009      Blount County  Alabama       Blount\n",
       "...     ...                ...      ...          ...\n",
       "3190  56037  Sweetwater County  Wyoming   Sweetwater\n",
       "3191  56039       Teton County  Wyoming        Teton\n",
       "3192  56041       Uinta County  Wyoming        Uinta\n",
       "3193  56043    Washakie County  Wyoming     Washakie\n",
       "3194  56045      Weston County  Wyoming       Weston\n",
       "\n",
       "[3144 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips_dictionary = {\n",
    "    '01': 'Alabama',\n",
    "    '02': 'Alaska',\n",
    "    '04': 'Arizona',\n",
    "    '05': 'Arkansas',\n",
    "    '06': 'California',\n",
    "    '08': 'Colorado',\n",
    "    '09': 'Connecticut',\n",
    "    '10': 'Delaware',\n",
    "    '11': 'District of Columbia',\n",
    "    '12': 'Florida',\n",
    "    '13': 'Georgia',\n",
    "    '15': 'Hawaii',\n",
    "    '16': 'Idaho',\n",
    "    '17': 'Illinois',\n",
    "    '18': 'Indiana',\n",
    "    '19': 'Iowa',\n",
    "    '20': 'Kansas',\n",
    "    '21': 'Kentucky',\n",
    "    '22': 'Louisiana',\n",
    "    '23': 'Maine',\n",
    "    '24': 'Maryland',\n",
    "    '25': 'Massachusetts',\n",
    "    '26': 'Michigan',\n",
    "    '27': 'Minnesota',\n",
    "    '28': 'Mississippi',\n",
    "    '29': 'Missouri',\n",
    "    '30': 'Montana',\n",
    "    '31': 'Nebraska',\n",
    "    '32': 'Nevada',\n",
    "    '33': 'New Hampshire',\n",
    "    '34': 'New Jersey',\n",
    "    '35': 'New Mexico',\n",
    "    '36': 'New York',\n",
    "    '37': 'North Carolina',\n",
    "    '38': 'North Dakota',\n",
    "    '39': 'Ohio',\n",
    "    '40': 'Oklahoma',\n",
    "    '41': 'Oregon',\n",
    "    '42': 'Pennsylvania',\n",
    "    '44': 'Rhode Island',\n",
    "    '45': 'South Carolina',\n",
    "    '46': 'South Dakota',\n",
    "    '47': 'Tennessee',\n",
    "    '48': 'Texas',\n",
    "    '49': 'Utah',\n",
    "    '50': 'Vermont',\n",
    "    '51': 'Virginia',\n",
    "    '53': 'Washington',\n",
    "    '54': 'West Virginia',\n",
    "    '55': 'Wisconsin',\n",
    "    '56': 'Wyoming'\n",
    "}\n",
    "\n",
    "url = 'https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt'\n",
    "\n",
    "# Fetch the content from the URL\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check that the request was successful\n",
    "\n",
    "table = response.text.split('------------    --------------\\n')[1]\n",
    "\n",
    "# Strip leading/trailing whitespace and split by newline\n",
    "lines = table.strip().split('\\n')\n",
    "\n",
    "# Create a DataFrame from the list of lines\n",
    "df = pd.DataFrame(lines, columns=['Data'])\n",
    "\n",
    "# Split the 'Data' column on the first space\n",
    "df[['FIPS', 'County_name']] = df['Data'].str.split(n=1, expand=True)\n",
    "\n",
    "# Drop the original 'Data' column\n",
    "df = df.drop(columns=['Data'])\n",
    "\n",
    "# Drop rows where 'FIPS' ends with '000'\n",
    "df = df[~df['FIPS'].str.endswith('000')]\n",
    "\n",
    "# Extract the first 2 digits from 'FIPS' column\n",
    "df['State_code'] = df['FIPS'].str[:2]\n",
    "\n",
    "# Map 'State_code' to 'State' using fips_dict\n",
    "df['State'] = df['State_code'].map(fips_dictionary)\n",
    "\n",
    "# just get the county\n",
    "df['County_short'] = df['County_name'].apply(lambda x: x.split(' County')[0])\n",
    "\n",
    "# Drop the 'State_code' column if not needed\n",
    "df_FIPS = df.drop(columns=['State_code'])\n",
    "\n",
    "df_Georgia = df_FIPS[df_FIPS['State'] == 'Georgia']\n",
    "\n",
    "df_FIPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas rapid fire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataset\n",
    "data = {\n",
    "    'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
    "    'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
    "    'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "    'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows where the age is missing\n",
    "df[df['age'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the rows the age is between 2 and 4 (inclusive)\n",
    "df[(df['age'] >= 2) & (df['age'] <= 4)]\n",
    "\n",
    "# df[df['age'].between(2, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the 'nunique', 'unique', and 'value_counts' methods for the 'animal' column\n",
    "df['animal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each unique animal, calculate the median age\n",
    "df.groupby('animal')['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort df first by the values in the 'age' in decending order, then by the value in the 'visits' column in ascending order\n",
    "df.sort_values(by=['age', 'visits'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which column of the following numbers has the largest, smallest sum?\n",
    "data = {\n",
    "    'A': [45, 67, 23, 89, 12],\n",
    "    'B': [78, 34, 56, 90, 21],\n",
    "    'C': [98, 23, 54, 65, 76],\n",
    "    'D': [12, 34, 87, 45, 68],\n",
    "    'E': [34, 89, 76, 54, 32],\n",
    "    'F': [56, 78, 90, 12, 34]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.sum()\n",
    "df.sum().sort_values(ascending=False)\n",
    "df.min().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each group, find the sum of the three greatest values\n",
    "df = pd.DataFrame({\n",
    "    'groups': list('aaabbcaabcccbbc'),\n",
    "    'vals': [12, 345, 3, 1, 45, 14, 4, 52, 54, 23, 235, 21, 57, 3, 87]\n",
    "})\n",
    "\n",
    "# step 1\n",
    "df.groupby('groups')['vals'].nlargest(3)\n",
    "\n",
    "# step 3\n",
    "# df.groupby('groups')['vals'].apply(lambda x: x.nlargest(3).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
